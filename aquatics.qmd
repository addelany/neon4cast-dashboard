---
title: "Aquatics"
engine: knitr
---

```{r setup, echo = FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning=FALSE)
library(ggiraph)
library(patchwork)
library(tidyverse)
library(neon4cast)
library(score4cast)
library(vis4cast)
library(glue)
source("R/plot-utils.R")
score4cast::ignore_sigpipe()

```

```{r include=FALSE}
cutoff <- as.character(Sys.Date() - 30)
combined <- arrow::open_dataset("cache/parquet/aquatics") |>
  filter(reference_datetime >= cutoff) |> collect()

```

```{r}
source("R/overview_map_test.R")
tmap_mode("view")
tm_shape(us_sf) +
  tm_bubbles(col ="crps_median", size = 'perc_skilled', id = 'field_site_name', title.col = 'CRPS skill relative to climatology',
             alpha = 0.5, xmod = 1,
             popup.vars = c('field_site_subtype','n_mod', 'perc_skilled'))
```


```{r}
source("R/test_synth_plots.R")

# plotting lakes 
  ggplot(lake_plot, aes(x=horizon, y = perc_skilled, group = site_id, colour = site_id)) +
  geom_line(linewidth = 1.2) +
  theme_bw(base_size = 20) +
  scale_colour_viridis_d(option = 'turbo', name = 'Site') +
  scale_fill_viridis_d(option = 'turbo', name = 'Site') +
  labs(y='% skillful forecasts', title = 'Water temperature forecasts') +
  theme(legend.position = 'right') +
  guides(color = guide_legend(nrow = 5)) +
  facet_wrap(~Type)

# plotting lakes and rivers
  ggplot(lakes_rivers_plot,aes(x=horizon, y = perc_skilled, group = Type, colour = Type)) +
  geom_line(linewidth = 1.2) +
  theme_bw(base_size = 20) +
  scale_colour_viridis_d(option = 'turbo', name = 'Type') +
  scale_fill_viridis_d(option = 'turbo', name = 'Type') +
  labs(y='% skillful forecasts', title = 'Water temperature forecasts') +
  theme(legend.position = 'right') +
  guides(color = guide_legend(nrow = 5))

```
## Forecasts

These plots show the most recently submitted forecast (a single `reference_datetime`) for which we have at least 10 observations.\
Models which did not submit a forecast on the given reference date are not shown.

```{r}
sites <- combined |> distinct(site_id) |> slice_head(n=6) |> collect() |> pull(site_id)
## with at least n observations to compare!
n_data <- 15
who <- combined |> filter(!is.na(observation)) |> summarise(has_data = max(reference_datetime)) |> collect()
ref <- as.character ( as.Date(who$has_data[[1]]) - n_data )
ex <- combined |> filter(reference_datetime == ref, site_id %in% sites) 
```

::: panel-tabset
## Oxygen

```{r}
ex |> filter(reference_datetime == ref, variable == "oxygen") |> forecast_plots()
```

## Temperature

```{r}
ex |> filter(reference_datetime == ref, variable == "temperature") |> forecast_plots()
```

## Chlorophyll-A

```{r}
ex |> filter(reference_datetime == ref, variable == "chla") |> forecast_plots()
```
:::

## Leaderboard

Average skill scores of each model across all sites. Scores are shown by reference date and forecast horizon (in days). Scores are averaged across all submissions of the model with a given horizon or a given `reference_datetime` out of submissions made since the cutoff date, `r cutoff`.

::: panel-tabset
## Oxygen

```{r}
leaderboard_plots(combined, "oxygen")
```

## Temperature

```{r}
leaderboard_plots(combined, "temperature")
```

## Chlorophyll-A

```{r}
leaderboard_plots(combined, "chla")
```
:::

## Submission statistics

```{r}
n_models <- combined |> distinct(model_id) |> nrow()
n_forecasts <- combined |> distinct(reference_datetime, model_id) |> nrow()
```

Between `r cutoff` and `r Sys.Date()`:

-   `r n_models` models have submitted a total of `r n_forecasts` forecasts to this challenge

```{r}
current_day <- Sys.Date()

combined |> 
  distinct(model_id, reference_datetime) |>
  count(model_id, sort=TRUE) |>
  filter(n > 1) |>
  mutate(model_id = fct_reorder(model_id, n)) |>
  ggplot(aes(model_id, n, fill=model_id)) +
  geom_col(show.legend = FALSE) + 
  coord_flip() + 
  theme_bw() + 
  theme(axis.text=element_text(size=6)) +
  ggtitle(glue("Number of forecast submissions since {cutoff}"))
```

## Long-term patterns

Here we look at some long term patterns in the median scores across all models. Are some months more predictable than others? Note that logs score penalties for observations that fall outside expected ranges are much higher than CRPS penalties.

```{r}
annual <- arrow::open_dataset("cache/parquet/aquatics") |>
  mutate(month = lubridate::month(datetime, label=TRUE)) |>
  group_by(month) |>
  summarise(crps = median(crps,na.rm=TRUE), 
            logs = median(logs, na.rm=TRUE))  |> 
  collect() |>
  pivot_longer(c(crps,logs), names_to="metric", values_to="score")

gg <- ggplot(annual) + 
  geom_col(aes(month, score, fill=metric), position="dodge") + theme_bw()

girafe(gg)
```

```{r}
sites <- arrow::open_dataset("cache/parquet/aquatics") |>
  group_by(site_id) |>
  summarise(crps = median(crps,na.rm=TRUE), 
            logs = median(logs, na.rm=TRUE))  |> 
  collect() |>
  mutate(site_id = fct_rev(fct_reorder(site_id, crps))) |>
  pivot_longer(c(crps,logs), names_to="metric", values_to="score")


gg <- sites |>
ggplot(aes(site_id, score, fill=metric)) + geom_col() +
  facet_wrap(~metric, ncol=1) + 
  guides(x =  guide_axis(angle = 45)) + theme_bw()

girafe(ggobj = gg)

```
